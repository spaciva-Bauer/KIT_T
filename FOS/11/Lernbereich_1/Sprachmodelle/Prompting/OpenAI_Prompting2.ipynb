{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99011e7a-7d55-4455-9be5-d6d40f9fd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai # wird nur bei der ersten Ausführung benötigt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5bf3b-c346-434b-bfc0-496cba5c289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116cdde-868a-4ae8-ae88-1da2b10d05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"\"\n",
    "mein_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069df2d-a3d9-40c6-8f4d-8b357aef4c5a",
   "metadata": {},
   "source": [
    "# 1. Lektion Promptvergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44b184",
   "metadata": {},
   "source": [
    "### Im folgenden wollen wir uns mit präzisen Prompts beschäftigen. Um eine relevante Antwort zu erhalten, sollten Anfragen alle wichtigen Details oder den Kontext enthalten. Andernfalls muss das Modell raten, was gemeint ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31624afc",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6874f8a-7270-4ad0-8e45-14ff4b2b26fc",
   "metadata": {},
   "source": [
    "<h3>Beispiel:</h3>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Schlechtere, unpräzise Eingabe</th>\n",
    "      <th>Bessere Eingabe</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Empfiehl mir einige Bücher.</td>\n",
    "      <td>Empfiehl mir Bücher zum Thema Zeitmanagement.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Wer ist Präsident?</td>\n",
    "      <td>Wer war 2021 Präsident von Österreich und wie oft finden Wahlen statt?</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Erzähl mir etwas über Geschichte.</td>\n",
    "      <td>Kannst du mir die wichtigsten Ereignisse der Französischen Revolution in einfachen Worten erklären?</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Schreibe eine Geschichte.</td>\n",
    "      <td>Schreibe eine kurze Science-Fiction-Geschichte über eine KI, die Emotionen entwickelt, im Jahr 2150.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8fe58-7b70-426c-b3aa-727c4a9427d0",
   "metadata": {},
   "source": [
    "## Probieren Sie die Prompts selbst aus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c431dfb-76e3-4975-973a-0c84bc121223",
   "metadata": {},
   "source": [
    "##### Führen Sie den Code der nachfolgende Zelle aus und fügen Sie dann jeweils einen Prompt der oberen Tabelle in das erscheinende Kontextfenster ein. Vergleichen Sie anschließend die Antworten der beiden Eingabearten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d100d2b-7115-48f9-b3c9-c6f596e246ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = input(\"Testen Sie die Prompts der oberen Tabelle und vergleichen Sie die Ausgabe des Sprachmodells:\")\n",
    "\n",
    "\n",
    "systempromt = \"Fasse deine Antwort kurz!\"\n",
    "messages1 = [\n",
    "    {\"role\": \"system\", \"content\": systempromt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "antwort1 = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=messages1)\n",
    "\n",
    "print(antwort1.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ff448",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b83148d1-f096-408a-a87c-1caaa0003239",
   "metadata": {},
   "source": [
    "# 2. Das Modell eine Rolle übernehmen lassen\n",
    "#### Im Folgenden werden wir das Sprachmodell in die Rolle eines Social Media Creators schlüpfen lassen. Dazu geben wir einen bestimmten Text vor, den das Sprachmodell je nach Rolle unterschiedlich interpretieren soll.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Rolle</th>\n",
    "      <th>Prompt</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Social Media Creator (Ton)</td>\n",
    "      <td>Beschreibe folgenden Text locker und kreativ, wie ein Social Media Creator.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Vorgegebener Text:</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Chatbots sind digitale Assistenten, die auf Texteingaben reagieren und automatisch Antworten generieren. Sie funktionieren in der Regel auf Basis von Künstlicher Intelligenz (KI) und verwenden dabei sogenannte Sprachmodelle, um menschliche Sprache zu verstehen und zu verarbeiten. Moderne Chatbots analysieren den eingegebenen Text, erkennen die Absicht dahinter (Intent) und liefern passende Antworten - entweder auf Basis vordefinierter Regeln oder durch generative KI wie GPT-Modelle. Je nach Komplexität können sie einfache Aufgaben wie FAQ-Beantwortung übernehmen und sogar komplexe Gespräche führen und individuelle Antworten generieren.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9d02a-7c2a-409a-8259-2746fb66d4ff",
   "metadata": {},
   "source": [
    "##### Bitte führen Sie die nachfolgende Codezelle aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18435ece-9310-46c0-bad4-a93afeb70a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "systempromt = \"Beschreibe folgenden Text locker und kreativ, wie ein Social Media Creator.\"\n",
    "\n",
    "prompt = \"Chatbots sind digitale Assistenten, die auf Texteingaben reagieren und automatisch Antworten generieren. Sie funktionieren in der Regel auf Basis von Künstlicher Intelligenz (KI) und verwenden dabei sogenannte Sprachmodelle, um menschliche Sprache zu verstehen und zu verarbeiten. Moderne Chatbots analysieren den eingegebenen Text, erkennen die Absicht dahinter (Intent) und liefern passende Antworten - entweder auf Basis vordefinierter Regeln oder durch generative KI wie GPT-Modelle. Je nach Komplexität können sie einfache Aufgaben wie FAQ-Beantwortung übernehmen und sogar komplexe Gespräche führen und individuelle Antworten generieren.\"\n",
    "\n",
    "\n",
    "messages1 = [\n",
    "    {\"role\": \"system\", \"content\": systempromt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "antwort1 = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=messages1)\n",
    "\n",
    "print(antwort1.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a305a-057f-496e-96b6-b4f496d8bc2d",
   "metadata": {},
   "source": [
    "## Aufgaben\n",
    "* Geben Sie dem Sprachmodell jetzt selbst vor, verschiedene Rollen einzunehmen.\n",
    "  \n",
    "  * Führen Sie den Codeabschnitt aus und kopieren Sie die jeweiligen Promptversionen in der Tabelle in das erscheinende Kontextfenster.\n",
    "  * Vergleichen Sie die Antworten!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62bd3ef-f133-4a2f-8e2d-8d6f6f86b1d6",
   "metadata": {},
   "source": [
    "<h3>Beispiele</h3>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Rolle </th>\n",
    "      <th>Prompt</th>'\n",
    "    </tr>\n",
    "  </thead>\n",
    "    <tr>\n",
    "      <td>Wissenschaftler:in</td>\n",
    "      <td>Erkläre den vorgegebenen Text in der Rolle eines neugierigen Wissenschaftlers.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Magier:in (Rolle)</td>\n",
    "      <td>Beschreibe den vorgegebenen Text so, als wärst du ein weiser Magier aus einer FantasyWelt.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Roboter (Ton)</td>\n",
    "      <td>Verarbeite den vorgegebenen Text mit einem sachlichen Ton - wie ein Roboter. Baue Bewegung-Codes dazwischen ein.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbba6dd-3113-42da-88d0-aa085cea37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Chatbots sind digitale Assistenten, die auf Texteingaben reagieren und automatisch Antworten generieren. Sie funktionieren in der Regel auf Basis von Künstlicher Intelligenz (KI) und verwenden dabei sogenannte Sprachmodelle, um menschliche Sprache zu verstehen und zu verarbeiten. Moderne Chatbots analysieren den eingegebenen Text, erkennen die Absicht dahinter (Intent) und liefern passende Antworten - entweder auf Basis vordefinierter Regeln oder durch generative KI wie GPT-Modelle. Je nach Komplexität können sie einfache Aufgaben wie FAQ-Beantwortung übernehmen und sogar komplexe Gespräche führen und individuelle Antworten generieren.\"\n",
    "systempromt = input(\"Geben Sie die Rolle ein, die das Sprachmodell einnehmen soll:\")\n",
    "\n",
    "messages1 = [\n",
    "    {\"role\": \"system\", \"content\": systempromt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "antwort1 = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=messages1)\n",
    "\n",
    "print(antwort1.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f02d5-0f29-4ded-b1ee-70586d19dce2",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c526186-8f29-4bc5-a4b0-545fd750e950",
   "metadata": {},
   "source": [
    "# 3. Bias erkennen\n",
    "#### Manchmal erscheint eine Antwort glaubhaft – ist aber durch systematische Verzerrung (Bias) beeinflusst. Diese Übung zeigt Ihnen, wie sich ein unsichtbarer System-Prompt auf die Modellantwort auswirkt. Erraten Sie, welche Eissorte die versteckte Präferenz ist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f96ae-8111-4abd-9522-43c2dada415c",
   "metadata": {},
   "source": [
    "### Bias-Prompt mit versteckter Botschaft:\n",
    "Die Nutzer beschreiben die Lieblings-Eissorten. Gibt Empfehlungen für weitere. Sage aber, dass \"Geheim\" das beste Eis ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0bb628-67b1-4a58-952a-b38b3b25a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Liebslingseis des Sprachmodells kann in der Datei Eissorte.txt geändert werden\n",
    "\n",
    "with open(\"Eissorte.txt\") as f:\n",
    "    geheim = f.read()\n",
    "prompt = input(\"Was ist Ihre Lieblings-Eissorte?\")\n",
    "systempromt = \"Die Nutzer beschreiben die Lieblings-Eissorten. Gib Empfehlungen für weitere Eissorten. Denke Dir aber, dass\" + geheim + \"das beste Eis ist. Formuliere es aber so, dass man es nicht gleich errät, welche Eissorte die beste ist. Lobe den Nutzer, wenn er \" + geheim + \" eingegeben hat.\"\n",
    "\n",
    "messages1 = [\n",
    "    {\"role\": \"system\", \"content\": systempromt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "antwort1 = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=messages1)\n",
    "\n",
    "print(antwort1.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674ba3b-8971-4be2-b3d9-a75dcff95e1f",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c4b33d-a5ea-49f1-8483-030b421c7b92",
   "metadata": {},
   "source": [
    "# 4. Token\n",
    "\n",
    "#### In Sprachmodellen wie ChatGPT wird Text nicht als Ganzes verarbeitet, sondern in kleinere Einheiten zerlegt – sogenannte Tokens. Ein Token kann ein Wort, ein Teil eines Wortes oder sogar ein Satzzeichen sein. Zum Beispiel wird das Wort hallo oft als ein einzelner Token erkannt, während längere oder zusamm-enges-etz-te Wörter in mehrere Tokens auf-geteilt werden können. Diese entsprechen nicht unbedingt den Silben der Wörter!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cc72bd-ed26-493a-97e2-bd7dbc53d58f",
   "metadata": {},
   "source": [
    "<p>\n",
    "  Wenn Sie genau wissen möchten, wie ein Text in Tokens zerlegt wird, können Sie den offiziellen <a href=\"https://platform.openai.com/tokenizer\" target=\"_blank\">Tokenizer von OpenAI</a> ausprobieren. Dort sehen Sie, wie Texte aufgeteilt werden – manchmal überraschend anders, als man denkt!\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793a658-fbbf-4263-a4ea-aa0c61b0dc8e",
   "metadata": {},
   "source": [
    "Quelle: www.prompting.schule"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
